{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-01T14:23:30.523908Z",
     "start_time": "2025-06-01T14:23:30.335477Z"
    }
   },
   "source": [
    "import huggingface_hub\n",
    "\n",
    "\n",
    "huggingface_hub.login(token=\"\")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2b\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2b\")\n",
    "\n",
    "input_text = \"What are you doing?\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model.generate(**input_ids)\n",
    "print(tokenizer.decode(outputs[0]))"
   ],
   "id": "bce99a899f5cb826",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "# pyaudio - install\n",
    "\n",
    "recognizer = sr.Recognizer()\n",
    "tts_engine = pyttsx3.init()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2b\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2b\")"
   ],
   "id": "cb3b9b07508c18c6",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T14:35:09.789010Z",
     "start_time": "2025-06-01T14:34:28.730801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def listen():\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Say something...\")\n",
    "        audio = recognizer.listen(source)\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio)\n",
    "        print(f\"You said: {text}\")\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(\"Could not understand audio.\")\n",
    "        return None\n",
    "\n",
    "import torch\n",
    "\n",
    "def ask_gemma(input_text):\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\")\n",
    "    outputs = model.generate(\n",
    "        **input_ids,\n",
    "        max_new_tokens=50,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    answer = tokenizer.decode(outputs[0][input_ids['input_ids'].shape[-1]:], skip_special_tokens=True)\n",
    "    return answer\n",
    "def speak(text):\n",
    "    tts_engine.say(text)\n",
    "    tts_engine.runAndWait()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    user_input = listen()\n",
    "    if user_input:\n",
    "        response = ask_gemma(user_input)\n",
    "        print(f\"Gemma: {response}\")\n",
    "        speak(response)"
   ],
   "id": "47461e1de6d5f28a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something...\n",
      "You said: tell me something about AI and\n",
      "Gemma:  how it is used in the real world.\n",
      "\n",
      "Answer:\n",
      "\n",
      "AI is used in the real world in a variety of ways. For example, AI can be used to help with decision-making, to improve efficiency, and to automate tasks. AI\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
